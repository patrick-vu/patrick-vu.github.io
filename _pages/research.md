---
title: 
layout: single
classes: wide
permalink: /research/
---
<br/> 

<!-- Google Tag Manager (noscript) -->
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-PNS829G"
height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
<!-- End Google Tag Manager (noscript) -->

# <center> Job Market Paper </center>

**How Do Standard Error Corrections Interact With Publication Bias? (Draft (coming soon) **<br/>
<small>
Econometrics research has devoted substantial efforts to improve the credibility of standard errors. This paper provides theoretical and empirical evidence on how improved standard errors interact with the selective publication process to affect the credibility of published studies. I show theoretically that adopting improved but enlarged standard errors at the individual-study level can exacerbate bias in published studies at the aggregate level, as larger effect sizes are required to maintain statistical significance. Nevertheless, coverage in published studies unambiguously improves. I empirically investigate these phenomena using newly collected data from the difference-in-differences literature, where the adoption of clustered standard errors rose from almost no use in the 1990's to near universal adoption by the end of the 2000's. Clustering led to substantial increases in the magnitude of published estimated treatment effects. I estimate an empirical model and find that clustering led to large improvements in coverage but also sizeable increases in bias.
</small><br><br/>

<small>
*Presented at 2023 Econometrics Society North American Summer Meeting*
<small>

# <center> Working Papers </center>
- - -

**Why Are Replication Rates So Low?** 2023.<br/>
<small>[ <a href="#/" onclick="visib('replication-rate')">Abstract</a> | [Draft][replication-rate-dp] | [Replication package][rr-replication] ] </small>

<div id="replication-rate" style="display: none; text-align: justify; line-height: 1.2" ><small>
This paper provides theoretical and empirical evidence for why replication rates are low in the social sciences. Theoretically, I show that we should expect replication rates to fall below their intended power targets owing to issues with common power calculations in replication studies, even in the case where original studies are unbiased and there is no p-hacking or treatment effect heterogeneity. Empirically, I find that the interaction of issues with common power calculations and low power in original studies can fully explain observed replication rates in experimental economics and social science, and two-thirds of the replication rate gap in psychology.
</small><br><br/></div>

[replication-rate-dp]:{{ site.baseurl }}{% link assets/files/20230314_replication_rate_draft.pdf %}
[rr-replication]: https://www.openicpsr.org/openicpsr/workspace?goToPath=/openicpsr/182521


**Do Content Warnings Help People Spot a Deepfake? Evidence from Two Experiments** (with [Andrew Lewis][alewis], [Raymond M. Duch][rduch] and [Areeq Chowdhury][achowdhury]). *Revise and Resubmit*.<br/>
<small>[ <a href="#/" onclick="visib('deepfake')">Abstract</a> | [Draft][deepfake-draft] | [Commissioned for the Royal Society Report on the Online Information Environment][rs-report] ] </small>

<div id="deepfake" style="display: none; text-align: justify; line-height: 1.2" ><small>
The rapid advancement of ‘deepfake’ video technology — which uses deep learning artificial intelligence algorithms to create fake videos that look real — has given urgency to the question of how policymakers and technology companies should moderate inauthentic content. We conduct an experiment to measure people’s alertness to and ability to detect a high-quality deepfake amongst a set of videos. First, we find that in a natural setting with no content warnings, individuals who are exposed to a deepfake video of neutral content are no more likely to detect anything out of the ordinary (32.9%) compared to a control group who viewed only authentic videos (34.1%). Second, we find that when individuals are given a warning that at least one video in a set of five videos is a deepfake, only 21.6% of respondents correctly identify the deepfake as the only inauthentic video, while the remainder erroneously select at least one genuine video as a deepfake.


</small><br><br/></div>

[deepfake-draft]: https://osf.io/v4bf6
[rs-report]: https://royalsociety.org/-/media/policy/projects/online-information-environment/the-online-information-environment.pdf
[alewis]: https://www.politics.ox.ac.uk/person/andrew-lewis
[rduch]: https://www.raymondduch.com/
[achowdhury]: https://areeqchowdhury.com/

# <center> Published Papers </center>
- - -
**Gender Inequality in Education and Kinship Norms in India** (with [Anu Rammohan][arammohan]). 2018. *Feminist Economics*.<br/>
<small>[ <a href="#/" onclick="visib('education-kinship')">Abstract</a> | [Paper][education-kinship] ] </small>

<div id="education-kinship" style="display: none; text-align: justify; line-height: 1.2" ><small>
Women’s schooling attainment in India continues to lag considerably behind that of men. This paper uses nationally representative district-level data from the 2007–8 District Level Household and Facility Survey (DLHS-3), Indicus Analytics, and the 2011–12 Indian Human Development Survey-II (IHDS-II) to examine the role of socioeconomic and cultural factors in influencing gender differentials in schooling. The results provide quantitative evidence of the role of different economic and sociocultural factors on gender disparities in education. The empirical results show that economic development is an important factor in narrowing gender gaps in education, with wealthier districts more likely to educate girls than poorer districts. However, the norm of patrilocal exogamy, where wives migrate to co-reside with their husband’s kin, is associated with worse outcomes for women’s schooling relative to men’s schooling; and, in keeping with anthropological research, gender-differentiated inequities in education are more pronounced in Northern India.
</small><br><br/></div>

[education-kinship]: https://econpapers.repec.org/article/taffemeco/v_3a24_3ay_3a2018_3ai_3a1_3ap_3a142-167.htm
[arammohan]: https://research-repository.uwa.edu.au/en/persons/anu-rammohan

# <center> Reserach in Progress </center>
- - -



**Statistical Treatment Choice With Selective Publication** (with [Toru Kitagawa][tkitagawa]).

[tkitagawa]: https://sites.google.com/brown.edu/torukitagawa


**How Do Individuals Learn? Evidence from Rwanda** (with [Aislinn Bohren][abohren], and [Daniel Björkegren][dbjorkegren]).

[abohren]: https://www.aislinnbohren.com/
[dbjorkegren]: https://dan.bjorkegren.com/

**Pollution Externalities and Environmental Adaptation: Evidence from Vietnam** (with [Michael Neubauer][mneubauer]).

[mneubauer]: https://ibes.brown.edu/people/michael-neubauer

[//]: This java script is the button to show abstract
<script>
 function visib(id) {
  var x = document.getElementById(id);
  if (x.style.display === "block") {
    x.style.display = "none";
  } else {
    x.style.display = "block";
  }
}
</script>

[//]:&emsp;<button onclick="visib('polariz')" class="btn btn--inverse btn--small">Abstract</button>
